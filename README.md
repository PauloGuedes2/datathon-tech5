# ğŸ“ **Passos MÃ¡gicos - PrevisÃ£o de Risco de Defasagem Escolar**

[![Python](https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-Latest-orange?style=for-the-badge&logo=scikit-learn)](https://scikit-learn.org)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue?style=for-the-badge&logo=docker)](https://docker.com)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

---

## ğŸ“‹ **Ãndice**

- [VisÃ£o Geral do Projeto](#visÃ£o-geral-do-projeto)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstruÃ§Ãµes de Deploy](#instruÃ§Ãµes-de-deploy)
- [Exemplos de Chamadas Ã  API](#exemplos-de-chamadas-Ã -api)
- [Pipeline de Machine Learning](#pipeline-de-machine-learning)
- [Arquitetura do Projeto](#arquitetura-do-projeto)
- [Monitoramento e Observabilidade](#monitoramento-e-observabilidade)
- [LicenÃ§a](#licenÃ§a)

---

## ğŸ¯ **VisÃ£o Geral do Projeto**

### **Problema de NegÃ³cio**

A **ONG Passos MÃ¡gicos** atende centenas de estudantes em situaÃ§Ã£o de vulnerabilidade social, oferecendo educaÃ§Ã£o complementar e apoio psicopedagÃ³gico. Um dos principais desafios Ã© identificar precocemente quais alunos estÃ£o em risco de defasagem escolar, permitindo intervenÃ§Ãµes direcionadas e personalizadas.

**Desafio**: Como identificar automaticamente estudantes que podem apresentar dificuldades acadÃªmicas antes que a defasagem se torne crÃ­tica?

### **SoluÃ§Ã£o Proposta**

Sistema de Machine Learning que analisa dados histÃ³ricos e caracterÃ­sticas dos estudantes para predizer a probabilidade de defasagem escolar. A soluÃ§Ã£o oferece:

- **Pipeline completa de ML**: Desde prÃ©-processamento atÃ© deploy em produÃ§Ã£o
- **API REST robusta**: IntegraÃ§Ã£o fÃ¡cil com sistemas existentes da ONG
- **PrediÃ§Ãµes em tempo real**: AnÃ¡lise instantÃ¢nea de novos estudantes
- **Arquitetura escalÃ¡vel**: Preparada para crescimento e novas funcionalidades

### **Objetivo Principal**

Identificar precocemente estudantes em risco de defasagem escolar atravÃ©s de anÃ¡lise preditiva, possibilitando que a ONG Passos MÃ¡gicos implemente estratÃ©gias de intervenÃ§Ã£o personalizadas e melhore os resultados educacionais.

### **CaracterÃ­sticas Principais**

- ğŸ§  **Modelo Random Forest** com F1-Score de 0.99
- ğŸ“Š **API REST** com FastAPI para prediÃ§Ãµes em tempo real
- ğŸ—ï¸ **Clean Architecture** (Domain, Application, Infrastructure, API)
- ğŸ³ **ContainerizaÃ§Ã£o** completa com Docker
- ğŸ“ˆ **MÃ©tricas de performance** detalhadas
- âš¡ **Processamento eficiente** de dados categÃ³ricos e numÃ©ricos

### **Stack TecnolÃ³gica**

| Componente | Tecnologia | VersÃ£o | PropÃ³sito |
|------------|------------|--------|-----------|
| **Linguagem** | Python | 3.11+ | Linguagem principal do projeto |
| **Framework ML** | Scikit-learn | Latest | Random Forest Classifier e pipeline |
| **Processamento** | Pandas + NumPy | Latest | ManipulaÃ§Ã£o e anÃ¡lise de dados |
| **API Framework** | FastAPI | Latest | REST API e documentaÃ§Ã£o automÃ¡tica |
| **ValidaÃ§Ã£o** | Pydantic | Latest | ValidaÃ§Ã£o de dados de entrada |
| **SerializaÃ§Ã£o** | Joblib | Latest | PersistÃªncia do modelo treinado |
| **Testes** | Pytest | Latest | Testes automatizados e cobertura |
| **ContainerizaÃ§Ã£o** | Docker + Compose | Latest | Deploy e orquestraÃ§Ã£o |
| **Monitoramento** | Logging + Health Checks | Built-in | Observabilidade da aplicaÃ§Ã£o |

---

## ğŸ“ **Estrutura do Projeto**

```
datathon-tech5/
â”œâ”€â”€ ğŸ“„ docker-compose.yml                    # OrquestraÃ§Ã£o de containers
â”œâ”€â”€ ğŸ“„ Dockerfile                            # Build da imagem Docker
â”œâ”€â”€ ğŸ“„ requirements.txt                      # DependÃªncias Python
â”œâ”€â”€ ğŸ“„ README.md                             # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ“„ LICENSE                               # LicenÃ§a MIT
â”‚
â”œâ”€â”€ ğŸ“ app/                                  # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ ğŸ“„ main.py                           # AplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ ğŸ“„ train.py                          # Script de treinamento
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ data/                             # Datasets
â”‚   â”‚   â””â”€â”€ ğŸ“„ PEDE_PASSOS_DATASET_FIAP.xlsx # Dataset principal
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ models/                           # Modelos treinados
â”‚   â”‚   â””â”€â”€ ğŸ“„ model_passos_magicos.joblib   # Modelo Random Forest
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ src/                              # CÃ³digo fonte organizado
â”‚       â”œâ”€â”€ ğŸ“ api/                          # Camada de API
â”‚       â”‚   â”œâ”€â”€ ğŸ“„ controller.py             # Controladores REST
â”‚       â”‚   â””â”€â”€ ğŸ“„ schemas.py                # Schemas Pydantic
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ application/                  # Camada de aplicaÃ§Ã£o
â”‚       â”‚   â””â”€â”€ ğŸ“„ risk_service.py           # ServiÃ§os de negÃ³cio
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ config/                       # ConfiguraÃ§Ãµes
â”‚       â”‚   â””â”€â”€ ğŸ“„ settings.py               # ConfiguraÃ§Ãµes centralizadas
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ domain/                       # Camada de domÃ­nio
â”‚       â”‚   â””â”€â”€ ğŸ“„ student.py                # Entidades de domÃ­nio
â”‚       â”‚
â”‚       â”œâ”€â”€ ğŸ“ infrastructure/               # Camada de infraestrutura
â”‚       â”‚   â”œâ”€â”€ ğŸ“ data/
â”‚       â”‚   â”‚   â””â”€â”€ ğŸ“„ data_loader.py        # Carregamento de dados
â”‚       â”‚   â””â”€â”€ ğŸ“ model/
â”‚       â”‚       â”œâ”€â”€ ğŸ“„ ml_pipeline.py        # Pipeline de ML
â”‚       â”‚       â””â”€â”€ ğŸ“„ feature_engineer.py   # Engenharia de features
â”‚       â”‚
â”‚       â””â”€â”€ ğŸ“ util/                         # UtilitÃ¡rios
â”‚           â””â”€â”€ ğŸ“„ logger.py                 # Sistema de logging
â”‚
â””â”€â”€ ğŸ“ tests/                                # Testes automatizados
    â”œâ”€â”€ ğŸ“„ conftest.py                       # ConfiguraÃ§Ãµes de teste
    â”œâ”€â”€ ğŸ“„ test_main.py                      # Testes da aplicaÃ§Ã£o
    â”œâ”€â”€ ğŸ“ api/                              # Testes da API
    â”œâ”€â”€ ğŸ“ application/                      # Testes de serviÃ§os
    â”œâ”€â”€ ğŸ“ infrastructure/                   # Testes de infraestrutura
    â””â”€â”€ ğŸ“ util/                             # Testes de utilitÃ¡rios
```

### **Responsabilidades por Camada**

#### **ğŸŒ API Layer** (`src/api/`)
- **controller.py**: Endpoints REST, validaÃ§Ã£o de entrada e tratamento de erros
- **schemas.py**: Modelos Pydantic para validaÃ§Ã£o e serializaÃ§Ã£o de dados

#### **ğŸ”§ Application Layer** (`src/application/`)
- **risk_service.py**: LÃ³gica de negÃ³cio para prediÃ§Ã£o de risco e regras de threshold

#### **ğŸ›ï¸ Domain Layer** (`src/domain/`)
- **student.py**: Entidade de domÃ­nio representando um estudante e suas caracterÃ­sticas

#### **ğŸ—ï¸ Infrastructure Layer** (`src/infrastructure/`)
- **ml_pipeline.py**: Pipeline completo de Machine Learning (treino, avaliaÃ§Ã£o, prediÃ§Ã£o)
- **feature_engineer.py**: TransformaÃ§Ãµes e encoding de features categÃ³ricas
- **data_loader.py**: Carregamento e validaÃ§Ã£o de dados do Excel

---

## ğŸš€ **InstruÃ§Ãµes de Deploy**

### **PrÃ©-requisitos**

| Requisito | VersÃ£o MÃ­nima | ObservaÃ§Ãµes |
|-----------|---------------|-------------|
| **Docker** | 20.10+ | Para containerizaÃ§Ã£o |
| **Docker Compose** | 2.0+ | Para orquestraÃ§Ã£o |
| **Git** | 2.0+ | Para clone do repositÃ³rio |
| **Python** | 3.11+ | Para execuÃ§Ã£o local (opcional) |
| **curl** | Qualquer | Para testes de API (opcional) |

### **ğŸ³ Deploy com Docker (Recomendado)**

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd datathon-tech5

# 2. Build e execuÃ§Ã£o com Docker Compose
docker-compose up -d --build

# 3. Verificar se o container estÃ¡ rodando
docker-compose ps

# 4. Verificar logs (opcional)
docker-compose logs -f passos-magicos-api

# 5. Testar a API
curl http://localhost:8000/health
```

**Comandos Docker Ãšteis:**
```bash
# Parar os serviÃ§os
docker-compose down

# Rebuild forÃ§ado
docker-compose up -d --build --force-recreate

# Ver logs em tempo real
docker-compose logs -f

# Entrar no container para debug
docker-compose exec passos-magicos-api bash
```

### **ğŸ’» InstalaÃ§Ã£o Local (Desenvolvimento)**

```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd datathon-tech5

# 2. Crie um ambiente virtual (recomendado)
python -m venv venv

# 3. Ative o ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Instale as dependÃªncias
pip install -r requirements.txt

# 5. CRUCIAL: Execute o treinamento do modelo
python app/train.py

# 6. Inicie a API
python app/main.py
```

> **âš ï¸ IMPORTANTE**: O comando `python app/train.py` Ã© **OBRIGATÃ“RIO** antes de iniciar a API, pois ele gera o arquivo `model_passos_magicos.joblib` necessÃ¡rio para as prediÃ§Ãµes.

### **ğŸ” VerificaÃ§Ã£o da InstalaÃ§Ã£o**

```bash
# 1. Health check da API
curl http://localhost:8000/health
# Resposta esperada: {"status":"ok","service":"passos-magicos-api"}

# 2. DocumentaÃ§Ã£o interativa (abrir no navegador)
# http://localhost:8000/docs

# 3. Teste de prediÃ§Ã£o simples
curl -X POST "http://localhost:8000/api/v1/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "IDADE_22": 14, "CG": 7.5, "CF": 7.0, "CT": 7.2,
       "IAA": 6.8, "IEG": 7.1, "IPS": 6.9, "IDA": 7.0,
       "MATEM": 6.5, "PORTUG": 7.3, "INGLES": 6.8,
       "GENERO": "M", "TURMA": "A", "INSTITUICAO_DE_ENSINO": "ESCOLA MUNICIPAL"
     }'
```

### **ğŸŒ Deploy no Render (ProduÃ§Ã£o)**

A aplicaÃ§Ã£o estÃ¡ hospedada no Render e pode ser acessada atravÃ©s do link:

**ğŸ”— URL de ProduÃ§Ã£o**: `https://datathon-tech5.onrender.com`

#### **ğŸ“‹ InformaÃ§Ãµes do Deploy**
- **Plataforma**: Render (Free Tier)
- **Build automÃ¡tico**: A cada push na branch `main`
- **DocumentaÃ§Ã£o**: `https://datathon-tech5.onrender.com/docs`
- **Health Check**: `https://datathon-tech5.onrender.com/health`

#### **âš ï¸ LimitaÃ§Ãµes do Plano Gratuito**
- **Sleep apÃ³s inatividade**: 15 minutos sem requests
- **Cold start**: ~30s para "acordar" o serviÃ§o  
- **RAM**: 512MB limitado
- **Build time**: 15 minutos mÃ¡ximo

> **ğŸ’¡ Dica**: O primeiro request apÃ³s perÃ­odo de inatividade pode demorar atÃ© 60 segundos devido ao cold start. Requests subsequentes sÃ£o rÃ¡pidos (~200-500ms).

---

## ğŸ“¡ **Exemplos de Chamadas Ã  API**

### **Base URLs**
- **ProduÃ§Ã£o (Render)**: `https://datathon-tech5.onrender.com`
- **Local**: `http://localhost:8000`

### **ğŸ“š DocumentaÃ§Ã£o Interativa**
- **Swagger UI**: `/docs` - Interface completa para testes
- **ReDoc**: `/redoc` - DocumentaÃ§Ã£o alternativa

**Links diretos:**
- ProduÃ§Ã£o: `https://datathon-tech5.onrender.com/docs`
- Local: `http://localhost:8000/docs`

---

### **ğŸ¥ Health Check**

```bash
GET /health
```

**Exemplos:**
```bash
# ProduÃ§Ã£o (Render)
curl https://datathon-tech5.onrender.com/health

# Local
curl http://localhost:8000/health
```

**Resposta:**
```json
{
  "status": "ok",
  "service": "passos-magicos-api",
  "environment": "render",
  "port": "10000"
}
```

---

### **ğŸ¯ Endpoint de PrediÃ§Ã£o**

```bash
POST /api/v1/predict
```

### **Exemplo com cURL**

```bash
# ProduÃ§Ã£o (Render) - Recomendado
curl -X POST "https://datathon-tech5.onrender.com/api/v1/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "IDADE_22": 14,
       "CG": 7.5,
       "CF": 7.0,
       "CT": 7.2,
       "IAA": 6.8,
       "IEG": 7.1,
       "IPS": 6.9,
       "IDA": 7.0,
       "MATEM": 6.5,
       "PORTUG": 7.3,
       "INGLES": 6.8,
       "GENERO": "M",
       "TURMA": "A",
       "INSTITUICAO_DE_ENSINO": "ESCOLA MUNICIPAL"
     }'

# Local (desenvolvimento)
curl -X POST "http://localhost:8000/api/v1/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "IDADE_22": 14,
       "CG": 7.5,
       "CF": 7.0,
       "CT": 7.2,
       "IAA": 6.8,
       "IEG": 7.1,
       "IPS": 6.9,
       "IDA": 7.0,
       "MATEM": 6.5,
       "PORTUG": 7.3,
       "INGLES": 6.8,
       "GENERO": "M",
       "TURMA": "A",
       "INSTITUICAO_DE_ENSINO": "ESCOLA MUNICIPAL"
     }'
```
```

### **Exemplo com Python**

```python
import requests
import json

# Configurar URL (produÃ§Ã£o recomendada)
BASE_URL = "https://datathon-tech5.onrender.com"  # ProduÃ§Ã£o
# BASE_URL = "http://localhost:8000"  # Local

url = f"{BASE_URL}/api/v1/predict"

# Dados do estudante
student_data = {
    "IDADE_22": 14,
    "CG": 7.5,
    "CF": 7.0,
    "CT": 7.2,
    "IAA": 6.8,
    "IEG": 7.1,
    "IPS": 6.9,
    "IDA": 7.0,
    "MATEM": 6.5,
    "PORTUG": 7.3,
    "INGLES": 6.8,
    "GENERO": "M",
    "TURMA": "A",
    "INSTITUICAO_DE_ENSINO": "ESCOLA MUNICIPAL"
}

# Fazer requisiÃ§Ã£o (timeout maior para cold start do Render)
try:
    response = requests.post(url, json=student_data, timeout=60)
    
    if response.status_code == 200:
        result = response.json()
        print("âœ… PrediÃ§Ã£o realizada com sucesso:")
        print(json.dumps(result, indent=2))
    else:
        print(f"âŒ Erro: {response.status_code} - {response.text}")
        
except requests.exceptions.Timeout:
    print("â° Timeout: API pode estar em cold start (aguarde ~60s)")
except requests.exceptions.RequestException as e:
    print(f"ğŸ”Œ Erro de conexÃ£o: {e}")
```

---

### **ğŸ“‹ Estrutura do Payload (Input)**

```json
{
  "IDADE_22": 14,           // int - Idade do estudante em 2022
  "CG": 7.5,                // float - CompetÃªncia Geral
  "CF": 7.0,                // float - CompetÃªncia em FÃ­sica
  "CT": 7.2,                // float - CompetÃªncia TÃ©cnica
  "IAA": 6.8,               // float - Indicador de Aprendizagem Ativa
  "IEG": 7.1,               // float - Indicador de Engajamento
  "IPS": 6.9,               // float - Indicador Psicossocial
  "IDA": 7.0,               // float - Indicador de Desenvolvimento AcadÃªmico
  "MATEM": 6.5,             // float - Nota em MatemÃ¡tica
  "PORTUG": 7.3,            // float - Nota em PortuguÃªs
  "INGLES": 6.8,            // float - Nota em InglÃªs
  "GENERO": "M",            // string - GÃªnero do estudante
  "TURMA": "A",             // string - Turma do estudante
  "INSTITUICAO_DE_ENSINO": "ESCOLA MUNICIPAL"  // string - InstituiÃ§Ã£o
}
```

**ValidaÃ§Ãµes:**
- **Features NumÃ©ricas**: Devem ser nÃºmeros (int/float)
- **Features CategÃ³ricas**: Devem ser strings nÃ£o vazias
- **Campos ObrigatÃ³rios**: Todos os 14 campos sÃ£o obrigatÃ³rios

---

### **ğŸ“¤ Estrutura da Resposta (Output)**

```json
{
  "risk_probability": 0.2847,
  "risk_label": "BAIXO RISCO",
  "message": "O estudante possui 28.5% de chance de defasagem."
}
```

**DescriÃ§Ã£o dos Campos:**
- `risk_probability` (float): Probabilidade de risco entre 0.0 e 1.0
- `risk_label` (string): "ALTO RISCO" (â‰¥0.5) ou "BAIXO RISCO" (<0.5)
- `message` (string): Mensagem explicativa com percentual formatado

---

### **âš ï¸ Tratamento de Erros**

#### **Erro 422 - ValidaÃ§Ã£o**
```json
{
  "detail": [
    {
      "loc": ["body", "IDADE_22"],
      "msg": "field required",
      "type": "value_error.missing"
    }
  ]
}
```

#### **Erro 500 - Interno**
```json
{
  "detail": "Modelo indisponÃ­vel. Execute 'train.py' primeiro."
}
```

---

## ğŸ”¬ **Pipeline de Machine Learning**

### **VisÃ£o Geral do Pipeline**

O pipeline de ML segue as melhores prÃ¡ticas de MLOps, desde a ingestÃ£o de dados atÃ© o deploy do modelo em produÃ§Ã£o. Cada etapa Ã© modular, testÃ¡vel e reproduzÃ­vel.

```mermaid
graph LR
    A[ğŸ“Š Dados Excel] --> B[ğŸ”„ PrÃ©-processamento]
    B --> C[âš™ï¸ Feature Engineering]
    C --> D[ğŸ§  Treinamento RF]
    D --> E[ğŸ“ˆ AvaliaÃ§Ã£o]
    E --> F[ğŸ’¾ PersistÃªncia]
    F --> G[ğŸš€ Deploy API]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#f1f8e9
    style G fill:#e0f2f1
```

---

### **1. ğŸ“Š IngestÃ£o de Dados**

**Fonte**: Dataset `PEDE_PASSOS_DATASET_FIAP.xlsx` com dados histÃ³ricos de estudantes da ONG.

```python
# Carregamento via DataLoader
from src.infrastructure.data.data_loader import DataLoader

loader = DataLoader()
df = loader.load_data()
print(f"Dataset carregado: {df.shape[0]} registros, {df.shape[1]} colunas")
```

**CaracterÃ­sticas do Dataset:**
- **Registros**: ~800 estudantes
- **Features**: 14 variÃ¡veis (11 numÃ©ricas + 3 categÃ³ricas)
- **Target**: Baseado na coluna DEFAS (defasagem escolar)
- **Formato**: Excel (.xlsx) com validaÃ§Ã£o automÃ¡tica

---

### **2. ğŸ”„ PrÃ©-processamento**

#### **Limpeza e NormalizaÃ§Ã£o**
```python
# PadronizaÃ§Ã£o de nomes de colunas
df.columns = df.columns.str.upper().str.strip()

# Tratamento de valores nulos
df = df.fillna(0)

# ValidaÃ§Ã£o de tipos de dados
numeric_cols = ['IDADE_22', 'CG', 'CF', 'CT', 'IAA', 'IEG', 'IPS', 'IDA', 'MATEM', 'PORTUG', 'INGLES']
df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')
```

#### **CriaÃ§Ã£o da VariÃ¡vel Target**
```python
# Target baseado na defasagem escolar
df["RISCO_DEFASAGEM"] = (df["DEFAS"] < 0).astype(int)
# 1 = ALTO RISCO (DEFAS < 0)
# 0 = BAIXO RISCO (DEFAS >= 0)

# DistribuiÃ§Ã£o das classes
print(df["RISCO_DEFASAGEM"].value_counts())
```

---

### **3. âš™ï¸ Engenharia de Features**

#### **Features NumÃ©ricas (11 variÃ¡veis)**
```python
FEATURES_NUMERICAS = [
    "IDADE_22",    # Idade do estudante em 2022
    "CG",          # CompetÃªncia Geral
    "CF",          # CompetÃªncia em FÃ­sica  
    "CT",          # CompetÃªncia TÃ©cnica
    "IAA",         # Indicador de Aprendizagem Ativa
    "IEG",         # Indicador de Engajamento
    "IPS",         # Indicador Psicossocial
    "IDA",         # Indicador de Desenvolvimento AcadÃªmico
    "MATEM",       # Nota em MatemÃ¡tica
    "PORTUG",      # Nota em PortuguÃªs
    "INGLES"       # Nota em InglÃªs
]
```

#### **Features CategÃ³ricas (3 variÃ¡veis)**
```python
FEATURES_CATEGORICAS = [
    "GENERO",                # GÃªnero do estudante
    "TURMA",                 # Turma do estudante  
    "INSTITUICAO_DE_ENSINO"  # InstituiÃ§Ã£o de ensino
]
```

#### **Label Encoding Inteligente**
```python
class FeatureEngineer(BaseEstimator, TransformerMixin):
    def transform(self, X):
        # Encoding com tratamento de valores nÃ£o vistos
        for col, encoder in self.encoders.items():
            X[col] = X[col].map(
                lambda s: encoder.transform([s])[0] if s in encoder.classes_ else -1
            )
        return X
```

**Vantagens:**
- Preserva estado dos encoders para produÃ§Ã£o
- Trata valores nÃ£o vistos durante treinamento
- Integrado ao pipeline sklearn

---

### **4. ğŸ§  SeleÃ§Ã£o e Treinamento do Modelo**

#### **Justificativa: Random Forest**

| CritÃ©rio | Random Forest | Alternativas |
|----------|---------------|--------------|
| **Interpretabilidade** | âœ… Feature importance | âŒ Deep Learning |
| **Robustez** | âœ… Resistente a overfitting | âŒ Ãrvore Ãºnica |
| **Features Mistas** | âœ… NumÃ©ricas + categÃ³ricas | âŒ RegressÃ£o linear |
| **Desbalanceamento** | âœ… class_weight="balanced" | âŒ SVM padrÃ£o |
| **Velocidade** | âœ… RÃ¡pido para prediÃ§Ã£o | âŒ Ensemble complexo |

#### **ConfiguraÃ§Ã£o do Modelo**
```python
RandomForestClassifier(
    n_estimators=200,           # 200 Ã¡rvores para estabilidade
    random_state=42,            # Reprodutibilidade
    class_weight="balanced",    # Balanceamento automÃ¡tico
    max_depth=None,             # Profundidade automÃ¡tica
    min_samples_split=2,        # DivisÃ£o mÃ­nima
    min_samples_leaf=1          # Folhas mÃ­nimas
)
```

#### **Pipeline Completo**
```python
pipeline = Pipeline([
    ("feature_engineer", FeatureEngineer()),    # Encoding categÃ³ricas
    ("classifier", RandomForestClassifier(...)) # Classificador
])

# Treinamento
pipeline.fit(X_train, y_train)
```

---

### **5. ğŸ“ˆ AvaliaÃ§Ã£o e ValidaÃ§Ã£o**

#### **DivisÃ£o Estratificada**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,              # 80% treino, 20% teste
    random_state=42,            # Reprodutibilidade
    stratify=y                  # MantÃ©m proporÃ§Ã£o das classes
)
```

#### **MÃ©tricas de Performance**
```python
# PrediÃ§Ãµes no conjunto de teste
y_pred = pipeline.predict(X_test)

# RelatÃ³rio completo
print(classification_report(y_test, y_pred, zero_division=0))
```

**MÃ©tricas Principais:**
- **F1-Score**: 0.99 (mÃ©trica principal para classes desbalanceadas)
- **Precision**: PrecisÃ£o na identificaÃ§Ã£o de risco
- **Recall**: Capacidade de detectar todos os casos de risco
- **Accuracy**: AcurÃ¡cia geral do modelo

#### **AnÃ¡lise de Feature Importance**
```python
# ExtraÃ§Ã£o automÃ¡tica da importÃ¢ncia
feature_names = FEATURES_NUMERICAS + FEATURES_CATEGORICAS
importances = pipeline.named_steps["classifier"].feature_importances_

# DataFrame ordenado por importÃ¢ncia
importance_df = pd.DataFrame({
    "feature": feature_names,
    "importance": importances
}).sort_values("importance", ascending=False)
```

---

### **6. ğŸ’¾ PersistÃªncia e Versionamento**

#### **Salvamento do Pipeline**
```python
import joblib
from pathlib import Path

# Salvamento completo do pipeline
model_path = "app/models/model_passos_magicos.joblib"
joblib.dump(pipeline, model_path)

print(f"Modelo salvo em: {model_path}")
print(f"Tamanho do arquivo: {Path(model_path).stat().st_size / 1024:.1f} KB")
```

#### **Artefatos Persistidos**
- **Pipeline Completo**: Modelo + feature engineering
- **Estado dos Encoders**: Para variÃ¡veis categÃ³ricas
- **MÃ©tricas de Performance**: Para monitoramento
- **ConfiguraÃ§Ãµes**: ParÃ¢metros e hiperparÃ¢metros

#### **Carregamento em ProduÃ§Ã£o**
```python
# Carregamento automÃ¡tico na API
class RiskService:
    def __init__(self):
        self.pipeline = joblib.load("app/models/model_passos_magicos.joblib")
    
    def predict_risk(self, student_data):
        probability = self.pipeline.predict_proba([student_data])[:, 1][0]
        return {
            "risk_probability": round(probability, 4),
            "risk_label": "ALTO RISCO" if probability >= 0.5 else "BAIXO RISCO"
        }
```

---

### **7. ğŸ”„ Retreinamento e Monitoramento**

#### **EstratÃ©gia de Retreinamento**
- **FrequÃªncia**: Semestral ou quando performance degrada
- **Trigger**: Monitoramento de drift nos dados
- **Processo**: Automatizado via `python app/train.py`
- **ValidaÃ§Ã£o**: A/B testing entre versÃµes

#### **Monitoramento de Performance**
```python
# Logs estruturados para monitoramento
logger.info(f"PrediÃ§Ã£o realizada: probabilidade={prob:.4f}")
logger.info(f"Features utilizadas: {list(X.columns)}")
logger.info(f"Tempo de resposta: {response_time:.3f}s")
```

---

## ğŸ—ï¸ **Arquitetura do Projeto**

### **Clean Architecture**

O projeto segue os princÃ­pios da Clean Architecture, garantindo separaÃ§Ã£o de responsabilidades, testabilidade e manutenibilidade.

```mermaid 
graph TB
    subgraph "ğŸŒ API Layer"
        Controller[PredictionController]
        Schemas[StudentDTO]
        FastAPI[FastAPI App]
    end
    
    subgraph "ğŸ”§ Application Layer"
        Service[RiskService]
    end
    
    subgraph "ğŸ›ï¸ Domain Layer"
        Student[Student Entity]
    end
    
    subgraph "ğŸ—ï¸ Infrastructure Layer"
        MLPipeline[MLPipeline]
        DataLoader[DataLoader]
        FeatureEngineer[FeatureEngineer]
    end
    
    subgraph "ğŸ’¾ External"
        Excel[Excel Dataset]
        Model[Trained Model]
    end
    
    FastAPI --> Controller
    Controller --> Schemas
    Controller --> Service
    Service --> Student
    Service --> MLPipeline
    MLPipeline --> FeatureEngineer
    DataLoader --> Excel
    MLPipeline --> Model
    
    classDef api fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef app fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef domain fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef infra fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef external fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class Controller,Schemas,FastAPI api
    class Service app
    class Student domain
    class MLPipeline,DataLoader,FeatureEngineer infra
    class Excel,Model external
```

### **Fluxo de PrediÃ§Ã£o**

```mermaid 
sequenceDiagram
    participant Client as ğŸ‘¤ Cliente
    participant API as ğŸŒ FastAPI
    participant Controller as ğŸ® Controller
    participant Service as ğŸ”§ RiskService
    participant Pipeline as ğŸ—ï¸ MLPipeline
    participant Model as ğŸ§  Random Forest

    Client->>+API: POST /api/v1/predict
    API->>+Controller: Validate Request
    Controller->>+Service: predict_risk(student)
    Service->>+Pipeline: predict_proba(dataframe)
    Pipeline->>Pipeline: Feature Engineering
    Pipeline->>+Model: Predict Probability
    Model->>-Pipeline: Risk Probability [0-1]
    Pipeline->>-Service: Processed Result
    Service->>Service: Apply Threshold (â‰¥0.5)
    Service->>-Controller: Risk Assessment
    Controller->>-API: JSON Response
    API->>-Client: Risk Prediction
```

### **PrincÃ­pios Arquiteturais**

#### **ğŸ”„ InversÃ£o de DependÃªncia**
```python
# Service depende de abstraÃ§Ã£o, nÃ£o implementaÃ§Ã£o
class RiskService:
    def __init__(self, ml_pipeline: MLPipeline):
        self.ml_pipeline = ml_pipeline
```

#### **ğŸ“¦ SeparaÃ§Ã£o de Responsabilidades**
- **API**: ValidaÃ§Ã£o, serializaÃ§Ã£o, HTTP
- **Application**: Regras de negÃ³cio, orquestraÃ§Ã£o
- **Domain**: Entidades, objetos de valor
- **Infrastructure**: Acesso a dados, ML, I/O

#### **ğŸ§ª Testabilidade**
```python
# InjeÃ§Ã£o de dependÃªncia facilita testes
def get_risk_service():
    return RiskService()

# Mocking em testes
@patch('src.application.risk_service.MLPipeline')
def test_predict_risk(mock_pipeline):
    # Test implementation
```

---

## ğŸ“Š **Monitoramento e Observabilidade**

### **ğŸ¥ Health Checks**

#### **Endpoint de SaÃºde**
```bash
GET /health
```

**VerificaÃ§Ãµes Realizadas:**
- Status da aplicaÃ§Ã£o
- Disponibilidade do modelo
- Conectividade com dependÃªncias

```python
@staticmethod
def health_check():
    return {
        "status": "ok",
        "service": "passos-magicos-api",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }
```

#### **Health Check Docker**
```dockerfile
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1
```

### **ğŸ“ Sistema de Logging**

#### **Logs Estruturados**
```python
import logging
from src.util.logger import logger

# ConfiguraÃ§Ã£o centralizada
logger.info("Iniciando prediÃ§Ã£o", extra={
    "student_id": student.id,
    "features_count": len(features),
    "model_version": "v1.0"
})
```

#### **NÃ­veis de Log**
- **INFO**: OperaÃ§Ãµes normais, prediÃ§Ãµes realizadas
- **WARNING**: Valores atÃ­picos, fallbacks ativados  
- **ERROR**: Falhas de modelo, dados invÃ¡lidos
- **DEBUG**: Detalhes tÃ©cnicos, debugging

### **ğŸ“ˆ MÃ©tricas de Performance**

#### **MÃ©tricas de AplicaÃ§Ã£o**
```python
# Tempo de resposta
start_time = time.time()
result = predict_risk(student)
response_time = time.time() - start_time

logger.info(f"PrediÃ§Ã£o concluÃ­da em {response_time:.3f}s")
```

#### **MÃ©tricas de Modelo**
```python
# DistribuiÃ§Ã£o de prediÃ§Ãµes
risk_distribution = {
    "alto_risco": predictions.count("ALTO RISCO"),
    "baixo_risco": predictions.count("BAIXO RISCO"),
    "probabilidade_media": np.mean(probabilities)
}
```

### **ğŸ” Monitoramento de Drift**

#### **Data Drift Detection**
```python
# ComparaÃ§Ã£o com dados de treinamento
def detect_feature_drift(new_data, reference_data):
    drift_scores = {}
    for feature in FEATURES_NUMERICAS:
        # KS test para features numÃ©ricas
        statistic, p_value = ks_2samp(
            reference_data[feature], 
            new_data[feature]
        )
        drift_scores[feature] = {"statistic": statistic, "p_value": p_value}
    return drift_scores
```

#### **Model Performance Monitoring**
```python
# Tracking de performance ao longo do tempo
performance_metrics = {
    "timestamp": datetime.now(),
    "predictions_count": len(predictions),
    "avg_probability": np.mean(probabilities),
    "high_risk_percentage": high_risk_count / total_predictions
}
```

### **ğŸš¨ Alertas e NotificaÃ§Ãµes**

#### **CondiÃ§Ãµes de Alerta**
- Taxa de erro > 5%
- Tempo de resposta > 2s
- Drift significativo detectado
- Modelo indisponÃ­vel

#### **Canais de NotificaÃ§Ã£o**
- Logs estruturados
- Health check failures
- Container restart policies

### **ğŸ“Š Dashboard de Monitoramento**

#### **MÃ©tricas Chave**
```bash
# Verificar mÃ©tricas via logs
docker-compose logs passos-magicos-api | grep "PrediÃ§Ã£o concluÃ­da"

# Status do container
docker-compose ps

# Uso de recursos
docker stats passos-magicos-container
```

#### **Comandos de Troubleshooting**
```bash
# Logs em tempo real
docker-compose logs -f --tail=100 passos-magicos-api

# Entrar no container para debug
docker-compose exec passos-magicos-api bash

# Verificar modelo treinado
ls -la app/models/

# Testar endpoint manualmente
curl -f http://localhost:8000/health
```

---

## ğŸ“„ **LicenÃ§a**

Este projeto estÃ¡ licenciado sob a **LicenÃ§a MIT** - veja o arquivo [LICENSE](LICENSE) para detalhes completos.

### **Resumo da LicenÃ§a**
- âœ… Uso comercial permitido
- âœ… ModificaÃ§Ã£o permitida  
- âœ… DistribuiÃ§Ã£o permitida
- âœ… Uso privado permitido
- âŒ Sem garantia
- âŒ Sem responsabilidade

---